<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="default.xsl"?>
<fr:tree
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"
toc="true"
numbered="true"
show-heading="true"
show-metadata="true"
expanded="true"
root="false"><fr:frontmatter><fr:anchor>181</fr:anchor><fr:addr>apl-0003</fr:addr><fr:route>apl-0003.xml</fr:route><fr:title>Lunar lander</fr:title><fr:date><fr:year>2024</fr:year><fr:month>7</fr:month><fr:day>15</fr:day></fr:date><fr:authors><fr:author>austinplane</fr:author></fr:authors></fr:frontmatter><fr:mainmatter><html:img
xmlns:html="http://www.w3.org/1999/xhtml"
src="https://media.giphy.com/media/v1.Y2lkPTc5MGI3NjExd251dnIxdWdjbGxsdDNoOXkwZXBybzVjcHoycW1seTA0bmFneWFrdCZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/VTMzq2QM2CW8Ywon4n/giphy.gif"></html:img><fr:p>Completed as part of the OMSCS course <fr:link
href="https://omscs.gatech.edu/cs-7642-reinforcement-learning"
type="external">CS 7642: Reinforcement Learning</fr:link>.</fr:p><fr:p>In this project, several RL agents based on variants of the Deep Q-Network (DQN) algorithm were implemented from scratch using Pytorch as the deep learning framework. The agents were tested in the Gym <fr:link
href="https://gymnasium.farama.org/"
type="external">Lunar Lander</fr:link> environment and evaluated for performance, training stability, and data efficiency. A systematic hyperparameter study was also carried out using the Optuna framework.</fr:p><fr:p>A full writeup of the project is <fr:link
href="Project2_AustinLane.pdf"
type="external">available</fr:link>.</fr:p></fr:mainmatter><fr:backmatter><fr:contributions></fr:contributions><fr:context><fr:tree
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"
toc="true"
numbered="false"
show-heading="true"
show-metadata="true"
expanded="true"
root="false"><fr:frontmatter><fr:anchor>179</fr:anchor><fr:addr>apl-0001</fr:addr><fr:route>apl-0001.xml</fr:route><fr:title>Selected projects</fr:title><fr:date><fr:year>2024</fr:year><fr:month>7</fr:month><fr:day>12</fr:day></fr:date><fr:authors><fr:author>austinplane</fr:author></fr:authors></fr:frontmatter><fr:mainmatter><fr:tree
xmlns:fr="http://www.jonmsterling.com/jms-005P.xml"
toc="true"
numbered="true"
show-heading="true"
show-metadata="false"
expanded="true"
root="false"><fr:frontmatter><fr:anchor>177</fr:anchor><fr:addr>apl-0003</fr:addr><fr:route>apl-0003.xml</fr:route><fr:title>Lunar lander</fr:title><fr:date><fr:year>2024</fr:year><fr:month>7</fr:month><fr:day>15</fr:day></fr:date><fr:authors><fr:author>austinplane</fr:author></fr:authors></fr:frontmatter><fr:mainmatter><html:img
xmlns:html="http://www.w3.org/1999/xhtml"
src="https://media.giphy.com/media/v1.Y2lkPTc5MGI3NjExd251dnIxdWdjbGxsdDNoOXkwZXBybzVjcHoycW1seTA0bmFneWFrdCZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/VTMzq2QM2CW8Ywon4n/giphy.gif"></html:img><fr:p>Completed as part of the OMSCS course <fr:link
href="https://omscs.gatech.edu/cs-7642-reinforcement-learning"
type="external">CS 7642: Reinforcement Learning</fr:link>.</fr:p><fr:p>In this project, several RL agents based on variants of the Deep Q-Network (DQN) algorithm were implemented from scratch using Pytorch as the deep learning framework. The agents were tested in the Gym <fr:link
href="https://gymnasium.farama.org/"
type="external">Lunar Lander</fr:link> environment and evaluated for performance, training stability, and data efficiency. A systematic hyperparameter study was also carried out using the Optuna framework.</fr:p><fr:p>A full writeup of the project is <fr:link
href="Project2_AustinLane.pdf"
type="external">available</fr:link>.</fr:p></fr:mainmatter></fr:tree></fr:mainmatter></fr:tree></fr:context><fr:related></fr:related><fr:backlinks></fr:backlinks><fr:references></fr:references></fr:backmatter></fr:tree>